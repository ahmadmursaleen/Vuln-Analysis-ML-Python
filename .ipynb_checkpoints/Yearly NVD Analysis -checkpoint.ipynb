{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2002 = pd.read_json('cve-2002.json')\n",
    "dataset2003 = pd.read_json('cve-2003.json')\n",
    "dataset2004 = pd.read_json('cve-2004.json')\n",
    "dataset2005 = pd.read_json('cve-2005.json')\n",
    "dataset2006 = pd.read_json('cve-2006.json')\n",
    "dataset2007 = pd.read_json('cve-2007.json')\n",
    "dataset2008 = pd.read_json('cve-2008.json')\n",
    "dataset2009 = pd.read_json('cve-2009.json')\n",
    "dataset2010 = pd.read_json('cve-2010.json')\n",
    "dataset2011 = pd.read_json('cve-2011.json')\n",
    "dataset2012 = pd.read_json('cve-2012.json')\n",
    "dataset2013 = pd.read_json('cve-2013.json')\n",
    "dataset2014 = pd.read_json('cve-2014.json')\n",
    "dataset2015 = pd.read_json('cve-2015.json')\n",
    "dataset2016 = pd.read_json('cve-2016.json')\n",
    "dataset2017 = pd.read_json('cve-2017.json')\n",
    "dataset2018 = pd.read_json('cve-2018.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yearly inclusions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = []\n",
    "severity = []\n",
    "scores = []\n",
    "exploitability = []\n",
    "\n",
    "test_description = []\n",
    "test_severity = []\n",
    "test_scores = []\n",
    "test_exploitability = []\n",
    "\n",
    "for i in range(dataset2018.shape[0]):\n",
    "    new=dataset2018.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        exploitability.append(new['impact']['baseMetricV2'][ 'exploitabilityScore'])\n",
    "        \n",
    "for i in range(dataset2017.shape[0]):\n",
    "    new=dataset2017.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        exploitability.append(new['impact']['baseMetricV2']['exploitabilityScore'])\n",
    "\n",
    "for i in range(dataset2016.shape[0]):\n",
    "    new=dataset2016.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "\n",
    "for i in range(dataset2015.shape[0]):\n",
    "    new=dataset2015.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "\n",
    "for i in range(dataset2014.shape[0]):\n",
    "    new=dataset2014.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])    \n",
    "\n",
    "for i in range(dataset2013.shape[0]):\n",
    "    new=dataset2013.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])       \n",
    "        \n",
    "for i in range(dataset2012.shape[0]):\n",
    "    new=dataset2012.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "for i in range(dataset2011.shape[0]):\n",
    "    new=dataset2011.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "\n",
    "for i in range(dataset2010.shape[0]):\n",
    "    new=dataset2010.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "\n",
    "for i in range(dataset2009.shape[0]):\n",
    "    new=dataset2009.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "for i in range(dataset2008.shape[0]):\n",
    "    new=dataset2008.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "#for i in range(dataset2007.shape[0]):\n",
    " #   new=dataset2007.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "#for i in range(dataset2006.shape[0]):\n",
    " #   new=dataset2006.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "#for i in range(dataset2005.shape[0]):\n",
    " #   new=dataset2005.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "#for i in range(dataset2004.shape[0]):\n",
    " #   new=dataset2004.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "#for i in range(dataset2003.shape[0]):\n",
    " #   new=dataset2003.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        \n",
    "#for i in range(dataset2002.shape[0]):\n",
    " #   new=dataset2002.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value']) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = np.array(description)\n",
    "severity = np.array(severity)\n",
    "scores = np.array(scores)\n",
    "exploitability = np.array(exploitability)\n",
    "\n",
    "test_description = np.array(description)\n",
    "test_severity = np.array(severity)\n",
    "test_scores = np.array(scores)\n",
    "test_exploitability = np.array(exploitability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_description = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in range(description.shape[0]):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_description.append( review_to_words( description[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_description_array = np.array(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the clean reviews\n",
    "test_clean_description = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in range(test_description.shape[0]):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    test_clean_description.append( review_to_words( test_description[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_description_array = np.array(test_clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "description_features = vectorizer.fit_transform(clean_description_array)\n",
    "#test_description_features = vectorizer.fit_transform(test_clean_description_array)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "description_features = description_features.toarray()\n",
    "#test_description_features = test_description_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7204157659936531\n",
      "0.8023271857609345\n",
      "0.8078373654677583\n",
      "0.7493330880323797\n",
      "0.7197332106715731\n",
      "avg 0.7599293231852597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "n_folds = 5\n",
    "score = 0.0\n",
    "skf = StratifiedKFold(severity, n_folds)\n",
    "avg_score = 0\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = severity[train_index], severity[test_index]\n",
    "    forest = RandomForestClassifier(n_estimators = 50)\n",
    "    forest.fit( X_train, y_train )\n",
    "    score = forest.score(X_test,y_test)\n",
    "    avg_score += score \n",
    "    print(score)\n",
    "    \n",
    "print(\"avg\",avg_score/n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on 18 and trainin on 17/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9903553797364893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "forest.fit( description_features, severity )\n",
    "\n",
    "score = forest.score( test_description_features,  test_severity)\n",
    "\n",
    "\n",
    "print(score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6878075702524951\n",
      "0.7675113829738307\n",
      "0.7924293993192899\n",
      "0.7344770490295282\n",
      "0.7050137994480221\n",
      "avg 0.7374478402046332\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "n_folds = 5\n",
    "score = 0.0\n",
    "skf = StratifiedKFold(severity, n_folds)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "avg_score = 0\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = severity[train_index], severity[test_index]\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    #YPred = forest.predict(X_test)\n",
    "    #y.append(YPred)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    print(score)\n",
    "    avg_score += score\n",
    "print(\"avg\",avg_score/n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6799889619647703\n",
      "0.744883410752886\n",
      "0.7761475485235949\n",
      "0.7358108729647687\n",
      "0.7125114995400184\n",
      "avg 0.7298684587492077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_folds = 5\n",
    "score = 0.0\n",
    "skf = StratifiedKFold(severity, n_folds)\n",
    "neigh = KNeighborsClassifier(n_neighbors=25)\n",
    "avg_score = 0\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = severity[train_index], severity[test_index]\n",
    "    \n",
    "    #YPred = forest.predict(X_test)\n",
    "    #y.append(YPred)\n",
    "    score = neigh.fit(X_train, y_train).score(X_test,y_test)\n",
    "    print(score)\n",
    "    avg_score += score\n",
    "print(\"avg\",avg_score/n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Scoring Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = np.array(scores).astype(np.float)\n",
    "exploitability_result = np.array(exploitability).astype(np.float)\n",
    "\n",
    "test_score_result = np.array(test_scores).astype(np.float)\n",
    "test_exploitability_result = np.array(test_exploitability).astype(np.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7591\n",
      "MAE: 0.6233\n",
      "MAE: 0.7976\n",
      "MAE: 0.7355\n",
      "MAE: 0.8243\n",
      "avg 0.7479518694443361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "  \n",
    "    clf = RandomForestRegressor(max_depth=45, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    #mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of folds n_folds=5 greater than the number of samples: 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9541c09ac76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mavg_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexploitability_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, y, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    536\u001b[0m                  random_state=None):\n\u001b[1;32m    537\u001b[0m         super(StratifiedKFold, self).__init__(\n\u001b[0;32m--> 538\u001b[0;31m             len(y), n_folds, shuffle, random_state)\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n, n_folds, shuffle, random_state)\u001b[0m\n\u001b[1;32m    260\u001b[0m             raise ValueError(\n\u001b[1;32m    261\u001b[0m                 (\"Cannot have number of folds n_folds={0} greater\"\n\u001b[0;32m--> 262\u001b[0;31m                  \" than the number of samples: {1}.\").format(n_folds, n))\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot have number of folds n_folds=5 greater than the number of samples: 0."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(exploitability_result, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = exploitability_result[train_index], exploitability_result[test_index]\n",
    "  \n",
    "    clf = RandomForestRegressor(max_depth=45, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    #mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on 2018 .... training on 16/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.3269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "clf = RandomForestRegressor(max_depth=45, random_state=0)\n",
    "clf.fit(description_features, score_result)\n",
    "#mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "mad = mean_absolute_error(test_score_result, clf.predict(test_description_features))\n",
    "#print(\"MSE: %.4f\" % mse)\n",
    "\n",
    "print(\"MAE: %.4f\" % mad)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing with scada descriptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_test = \"Delta PMSoft versions 2.10 and prior have multiple stack-based buffer overflow vulnerabilities where a .ppm file can introduce a value larger than is readable by PMSoft's fixed-length stack buffer. This can cause the buffer to be overwritten, which may allow arbitrary code execution or cause the application to crash. CVSS v3 base score: 7.1; CVSS vector string: AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:H. Delta Electronics recommends affected users update to at least PMSoft v2.11, which was made available as of March 22, 2018, or the latest available version.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Delta PMSoft versions 2.10 and prior have multiple stack-based buffer overflow vulnerabilities where a .ppm file can introduce a value larger than is readable by PMSoft's fixed-length stack buffer. This can cause the buffer to be overwritten, which may allow arbitrary code execution or cause the application to crash. CVSS v3 base score: 7.1; CVSS vector string: AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:H/A:H. Delta Electronics recommends affected users update to at least PMSoft v2.11, which was made available as of March 22, 2018, or the latest available version.\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_desc_test = review_to_words (desc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'delta pmsoft versions prior multiple stack based buffer overflow vulnerabilities ppm file introduce value larger readable pmsoft fixed length stack buffer cause buffer overwritten may allow arbitrary code execution cause application crash cvss v base score cvss vector string av l ac l pr n ui r u c n h h delta electronics recommends affected users update least pmsoft v made available march latest available version'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_desc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_desc_test = np.array(clean_desc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-0e7ed857bcef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_desc_test_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_desc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_int_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
     ]
    }
   ],
   "source": [
    "clean_desc_test_features = vectorizer.fit_transform(clean_desc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
