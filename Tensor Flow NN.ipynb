{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json('cve-2016.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = []\n",
    "severity = []\n",
    "scores = []\n",
    "\n",
    "for i in range(dataset.shape[0]):\n",
    "    new=dataset.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = np.array(description)\n",
    "severity = np.array(severity)\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_result = np.array(scores).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_description = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in range(description.shape[0]):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_description.append( review_to_words( description[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_description_array = np.array(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "description_features = vectorizer.fit_transform(clean_description_array)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "description_features = description_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.809585 5.8462367\n",
      "5 5.160324 5.2313447\n",
      "10 4.2164226 4.246761\n",
      "15 2.9862418 2.9408264\n",
      "20 2.5988214 2.5132635\n",
      "25 2.5496793 2.5486178\n",
      "30 2.2028866 2.3043842\n",
      "35 2.2061298 2.329694\n",
      "40 2.134942 2.26963\n",
      "45 2.0858686 2.248738\n",
      "50 2.0794406 2.2617583\n",
      "55 2.04184 2.2180786\n",
      "60 2.0302649 2.1936624\n",
      "65 2.0178003 2.1843233\n",
      "70 2.0057778 2.1821067\n",
      "75 1.9960316 2.1751335\n",
      "80 1.9873366 2.158892\n",
      "85 1.9803038 2.1441638\n",
      "90 1.9724272 2.1340103\n",
      "95 1.9656241 2.1253836\n",
      "Training is complete!\n",
      "Final Training cost: 1.9599733352661133\n",
      "Final Testing cost: 2.116116523742676\n",
      "0 6.3137636 6.2920585\n",
      "5 5.868054 5.8787446\n",
      "10 5.4937167 5.4885683\n",
      "15 4.9287376 4.952388\n",
      "20 4.118076 4.2019634\n",
      "25 3.10795 3.1922522\n",
      "30 2.6273646 2.5404053\n",
      "35 2.6899126 2.554878\n",
      "40 2.353303 2.2635539\n",
      "45 2.248467 2.1674213\n",
      "50 2.2123804 2.126564\n",
      "55 2.135391 2.0603943\n",
      "60 2.1185682 2.0704641\n",
      "65 2.09118 2.0492766\n",
      "70 2.0647955 2.0151448\n",
      "75 2.0486777 2.00189\n",
      "80 2.0305424 1.9952497\n",
      "85 2.017988 1.9920549\n",
      "90 2.0043027 1.9815844\n",
      "95 1.9927137 1.9734163\n",
      "Training is complete!\n",
      "Final Training cost: 1.9831268787384033\n",
      "Final Testing cost: 1.969703197479248\n",
      "0 6.0931044 6.107996\n",
      "5 5.6935997 5.6785045\n",
      "10 5.110418 5.07619\n",
      "15 4.2169714 4.1914697\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-141517419b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# Feed in the training data and do one step of neural network training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# Every 5 training steps, log our progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    Y_train, Y_test = score_result[train_index], score_result[test_index]\n",
    "    \n",
    "    \n",
    "    # Define model parameters\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 100\n",
    "\n",
    "    # Define how many inputs and outputs are in our neural network\n",
    "    number_of_inputs = 500\n",
    "    number_of_outputs = 1\n",
    "\n",
    "    # Define how many neurons we want in each layer of our neural network\n",
    "    layer_1_nodes = 50\n",
    "    layer_2_nodes = 100\n",
    "    layer_3_nodes = 50\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    with tf.variable_scope('input'):\n",
    "        X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "    # Layer 1\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "    # Layer 2\n",
    "    with tf.variable_scope('layer_2'):\n",
    "        weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "    # Layer 3\n",
    "    with tf.variable_scope('layer_3'):\n",
    "        weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "    # Output Layer\n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, number_of_outputs])\n",
    "        biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        prediction = tf.matmul(layer_3_output, weights) + biases\n",
    "\n",
    "    # Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "    with tf.variable_scope('cost'):\n",
    "        Y = tf.placeholder(tf.float32)\n",
    "        cost = tf.reduce_mean(abs(prediction-Y))\n",
    "    \n",
    "    # Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize a session so that we can run TensorFlow operations\n",
    "    with tf.Session() as session:\n",
    "\n",
    "        # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Run the optimizer over and over to train the network.\n",
    "        # One epoch is one full run through the training data set.\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Feed in the training data and do one step of neural network training\n",
    "            session.run(optimizer, feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Every 5 training steps, log our progress\n",
    "            if epoch % 5 == 0:\n",
    "                training_cost = session.run(cost, feed_dict={X: X_train, Y:Y_train})\n",
    "                testing_cost = session.run(cost, feed_dict={X: X_test, Y:Y_test})\n",
    "\n",
    "                print(epoch, training_cost, testing_cost)\n",
    "\n",
    "        # Training is now complete!\n",
    "        print(\"Training is complete!\")\n",
    "\n",
    "        final_training_cost = session.run(cost, feed_dict={X: X_train, Y: Y_train})\n",
    "        final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "        print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.3913636 6.330703\n",
      "5 5.9288187 5.916041\n",
      "10 5.5377703 5.5372915\n",
      "15 5.135031 5.1657634\n",
      "20 4.736758 4.78527\n",
      "25 4.3379664 4.392524\n",
      "30 3.9444056 4.0002966\n",
      "35 3.5720854 3.6296792\n",
      "40 3.2340565 3.2989545\n",
      "45 2.943415 3.0183892\n",
      "50 2.7128747 2.8018372\n",
      "55 2.5437698 2.6515915\n",
      "60 2.4343283 2.5563335\n",
      "65 2.3604124 2.4999278\n",
      "70 2.3145652 2.4660306\n",
      "75 2.279439 2.4442096\n",
      "80 2.2531784 2.4279125\n",
      "85 2.2313697 2.4141328\n",
      "90 2.2133071 2.4030728\n",
      "95 2.1971588 2.3945718\n",
      "100 2.1838992 2.387891\n",
      "105 2.1721396 2.382463\n",
      "110 2.162445 2.3777144\n",
      "115 2.154373 2.3734365\n",
      "120 2.1467428 2.3697414\n",
      "125 2.1401405 2.3663604\n",
      "130 2.133463 2.3634777\n",
      "135 2.1269307 2.360345\n",
      "140 2.121909 2.3576157\n",
      "145 2.1158257 2.354647\n",
      "150 2.1107652 2.3515654\n",
      "155 2.1055086 2.34805\n",
      "160 2.100851 2.3449965\n",
      "165 2.097205 2.3415732\n",
      "170 2.0933006 2.3382661\n",
      "175 2.0886867 2.3346088\n",
      "180 2.0846198 2.3310363\n",
      "185 2.0806203 2.327309\n",
      "190 2.076965 2.3236957\n",
      "195 2.0726862 2.3197658\n",
      "Training is complete!\n",
      "Final Training cost: 2.0701630115509033\n",
      "Final Testing cost: 2.3166565895080566\n",
      "0 6.386008 6.3886228\n",
      "5 5.9259405 5.9336896\n",
      "10 5.503696 5.504508\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1f36b794ce08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# Feed in the training data and do one step of neural network training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Every 5 training steps, log our progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    Y_train, Y_test = score_result[train_index], score_result[test_index]\n",
    "    \n",
    "    \n",
    "    #regularisation\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(scale=0.01)\n",
    "    \n",
    "    # Define model parameters\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 200\n",
    "\n",
    "    # Define how many inputs and outputs are in our neural network\n",
    "    number_of_inputs = 500\n",
    "    number_of_outputs = 1\n",
    "\n",
    "    # Define how many neurons we want in each layer of our neural network\n",
    "    layer_1_nodes = 50\n",
    "    layer_2_nodes = 100\n",
    "    layer_3_nodes = 50\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    with tf.variable_scope('input'):\n",
    "        X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "    # Layer 1\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(\"weights1\", regularizer=regularizer,shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "\n",
    "    # Output Layer\n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(\"weights4\", regularizer=regularizer, shape=[layer_1_nodes, number_of_outputs])\n",
    "        biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        prediction = tf.matmul(layer_1_output, weights) + biases\n",
    "\n",
    "    # Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "    with tf.variable_scope('cost'):\n",
    "        Y = tf.placeholder(tf.float32)\n",
    "        cost = tf.reduce_mean(abs(prediction-Y))\n",
    "    \n",
    "    # Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize a session so that we can run TensorFlow operations\n",
    "    with tf.Session() as session:\n",
    "\n",
    "        # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Run the optimizer over and over to train the network.\n",
    "        # One epoch is one full run through the training data set.\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Feed in the training data and do one step of neural network training\n",
    "            session.run(optimizer, feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Every 5 training steps, log our progress\n",
    "            if epoch % 5 == 0:\n",
    "                training_cost = session.run(cost, feed_dict={X: X_train, Y:Y_train})\n",
    "                testing_cost = session.run(cost, feed_dict={X: X_test, Y:Y_test})\n",
    "\n",
    "                print(epoch, training_cost, testing_cost)\n",
    "\n",
    "        # Training is now complete!\n",
    "        print(\"Training is complete!\")\n",
    "\n",
    "        final_training_cost = session.run(cost, feed_dict={X: X_train, Y: Y_train})\n",
    "        final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "        print(\"Final Testing cost: {}\".format(final_testing_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.083245 6.080838\n",
      "5 5.5260377 5.5600276\n",
      "10 4.971763 5.038488\n",
      "15 4.4246273 4.5104346\n",
      "20 3.9139543 3.9918978\n",
      "25 3.4488997 3.524602\n",
      "30 3.0483305 3.1278381\n",
      "35 2.7404468 2.828259\n",
      "40 2.53088 2.6351495\n",
      "45 2.4048758 2.5277576\n",
      "50 2.334103 2.4732242\n",
      "55 2.2906017 2.4425502\n",
      "60 2.2589564 2.4197042\n",
      "65 2.2281182 2.3995092\n",
      "70 2.202884 2.38372\n",
      "75 2.1825671 2.3724823\n",
      "80 2.1671972 2.364674\n",
      "85 2.1542888 2.3584723\n",
      "90 2.144201 2.3531485\n",
      "95 2.1350422 2.348176\n",
      "100 2.1265638 2.3436902\n",
      "105 2.1175482 2.3393404\n",
      "110 2.1106508 2.3347213\n",
      "115 2.1047485 2.3300486\n",
      "120 2.098937 2.3253934\n",
      "125 2.0932546 2.3205848\n",
      "130 2.0880895 2.315838\n",
      "135 2.0822582 2.3107066\n",
      "140 2.0773337 2.3060513\n",
      "145 2.073586 2.3012295\n",
      "150 2.068536 2.2963436\n",
      "155 2.0648196 2.2918763\n",
      "160 2.0598803 2.2871017\n",
      "165 2.0558808 2.2826457\n",
      "170 2.052055 2.2777278\n",
      "175 2.0484335 2.2728\n",
      "180 2.0448995 2.2680101\n",
      "185 2.0410495 2.2634091\n",
      "190 2.037872 2.258481\n",
      "195 2.033979 2.2536285\n",
      "Training is complete!\n",
      "Final Training cost: 2.031540870666504\n",
      "Final Testing cost: 2.2498011589050293\n",
      "0 5.786031 5.7584634\n",
      "5 5.276452 5.24619\n",
      "10 4.7634377 4.7501187\n",
      "15 4.2564397 4.2635527\n",
      "20 3.763897 3.7807336\n",
      "25 3.3099797 3.3099504\n",
      "30 2.9288201 2.879146\n",
      "35 2.6489623 2.5442593\n",
      "40 2.4751177 2.3303452\n",
      "45 2.3823915 2.2176428\n",
      "50 2.3349264 2.163645\n",
      "55 2.3025234 2.140226\n",
      "60 2.272921 2.124854\n",
      "65 2.2469532 2.1120722\n",
      "70 2.2247584 2.1003363\n",
      "75 2.2082613 2.0902684\n",
      "80 2.1953907 2.0815587\n",
      "85 2.183322 2.0747714\n",
      "90 2.1739733 2.0689385\n",
      "95 2.1655912 2.0635607\n",
      "100 2.1566525 2.0588613\n",
      "105 2.149286 2.054494\n",
      "110 2.1417162 2.0503848\n",
      "115 2.135081 2.0465348\n",
      "120 2.128687 2.042894\n",
      "125 2.1223211 2.039422\n",
      "130 2.1166208 2.0362449\n",
      "135 2.111051 2.0333471\n",
      "140 2.1053548 2.030591\n",
      "145 2.1002746 2.0280256\n",
      "150 2.0952697 2.0257974\n",
      "155 2.0905244 2.0235007\n",
      "160 2.0863369 2.0213807\n",
      "165 2.0814583 2.019396\n",
      "170 2.0768123 2.0173519\n",
      "175 2.0723486 2.0154889\n",
      "180 2.0683796 2.013409\n",
      "185 2.0639787 2.011601\n",
      "190 2.060075 2.009731\n",
      "195 2.0561123 2.007988\n",
      "Training is complete!\n",
      "Final Training cost: 2.0533547401428223\n",
      "Final Testing cost: 2.0065207481384277\n",
      "0 5.8722553 5.874944\n",
      "5 5.2967777 5.289318\n",
      "10 4.730514 4.7286253\n",
      "15 4.172605 4.1904984\n",
      "20 3.6481903 3.6828492\n",
      "25 3.1920922 3.2236845\n",
      "30 2.827173 2.8439672\n",
      "35 2.5852838 2.5776653\n",
      "40 2.446994 2.4183152\n",
      "45 2.3764029 2.3357441\n",
      "50 2.3387005 2.2936857\n",
      "55 2.3070948 2.263823\n",
      "60 2.2776423 2.2371588\n",
      "65 2.2515697 2.2135673\n",
      "70 2.2304595 2.1949704\n",
      "75 2.213401 2.1802068\n",
      "80 2.2003808 2.1689966\n",
      "85 2.1907675 2.15936\n",
      "90 2.179741 2.1498966\n",
      "95 2.169519 2.1411004\n",
      "100 2.161231 2.1332774\n",
      "105 2.1525738 2.1262095\n",
      "110 2.1449878 2.119555\n",
      "115 2.13767 2.1135612\n",
      "120 2.1307268 2.1081827\n",
      "125 2.1245189 2.1029258\n",
      "130 2.1180696 2.0984974\n",
      "135 2.1126537 2.09404\n",
      "140 2.1078687 2.0902355\n",
      "145 2.1021779 2.0865002\n",
      "150 2.0966923 2.0831409\n",
      "155 2.0912092 2.079788\n",
      "160 2.0869124 2.0768535\n",
      "165 2.0826051 2.0739443\n",
      "170 2.0790567 2.0713716\n",
      "175 2.0751283 2.0687284\n",
      "180 2.0720415 2.0664299\n",
      "185 2.0684783 2.0640426\n",
      "190 2.0643828 2.0617573\n",
      "195 2.0611863 2.059693\n",
      "Training is complete!\n",
      "Final Training cost: 2.0586845874786377\n",
      "Final Testing cost: 2.05816650390625\n",
      "0 6.003251 6.0009375\n",
      "5 5.5456467 5.546373\n",
      "10 5.0589247 5.0673103\n",
      "15 4.5497584 4.5540247\n",
      "20 4.034681 4.0333495\n",
      "25 3.561919 3.535421\n",
      "30 3.1461713 3.0988853\n",
      "35 2.8193307 2.7726498\n",
      "40 2.5958555 2.5585785\n",
      "45 2.461613 2.4354646\n",
      "50 2.3848336 2.3735893\n",
      "55 2.3369153 2.3382103\n",
      "60 2.2982998 2.3076613\n",
      "65 2.2672374 2.2773237\n",
      "70 2.2413843 2.2498527\n",
      "75 2.2221472 2.2279947\n",
      "80 2.207646 2.2105472\n",
      "85 2.1952562 2.1963797\n",
      "90 2.1836543 2.1846797\n",
      "95 2.1732273 2.1742082\n",
      "100 2.1631167 2.165288\n",
      "105 2.1544719 2.1570706\n",
      "110 2.1463413 2.149796\n",
      "115 2.1387305 2.1428277\n",
      "120 2.1325114 2.1362693\n",
      "125 2.1261013 2.1302793\n",
      "130 2.1203005 2.1242847\n",
      "135 2.11481 2.118746\n",
      "140 2.1088216 2.1140485\n",
      "145 2.103245 2.1090016\n",
      "150 2.097926 2.1047196\n",
      "155 2.0930274 2.1006134\n",
      "160 2.088081 2.0965412\n",
      "165 2.0831625 2.0928378\n",
      "170 2.0787213 2.0891888\n",
      "175 2.074456 2.086069\n",
      "180 2.070619 2.0830286\n",
      "185 2.0668306 2.0800366\n",
      "190 2.0631332 2.076991\n",
      "195 2.0599709 2.0743442\n",
      "Training is complete!\n",
      "Final Training cost: 2.0569071769714355\n",
      "Final Testing cost: 2.0722782611846924\n",
      "0 5.8064704 5.7994876\n",
      "5 5.276487 5.2141395\n",
      "10 4.7305403 4.65042\n",
      "15 4.1816673 4.1109486\n",
      "20 3.6428988 3.6145203\n",
      "25 3.1623962 3.2038553\n",
      "30 2.777672 2.9087696\n",
      "35 2.5253992 2.7344189\n",
      "40 2.3897297 2.648426\n",
      "45 2.3254619 2.6035998\n",
      "50 2.2896852 2.5651326\n",
      "55 2.2620988 2.5207853\n",
      "60 2.2332084 2.467924\n",
      "65 2.2075698 2.4195442\n",
      "70 2.187628 2.3826606\n",
      "75 2.1702995 2.3570383\n",
      "80 2.1585033 2.339875\n",
      "85 2.147122 2.3270495\n",
      "90 2.1368384 2.3164332\n",
      "95 2.128505 2.306792\n",
      "100 2.1195886 2.2983844\n",
      "105 2.1117687 2.2917898\n",
      "110 2.1043434 2.286257\n",
      "115 2.0971017 2.2811835\n",
      "120 2.0913007 2.2769423\n",
      "125 2.0853148 2.2730267\n",
      "130 2.0799198 2.2690527\n",
      "135 2.0745983 2.2656088\n",
      "140 2.069324 2.2622397\n",
      "145 2.0640712 2.2592444\n",
      "150 2.059761 2.2559388\n",
      "155 2.0556314 2.2530465\n",
      "160 2.0514395 2.2502763\n",
      "165 2.0470777 2.2474878\n",
      "170 2.0431151 2.244634\n",
      "175 2.0398836 2.2423286\n",
      "180 2.0364077 2.2397652\n",
      "185 2.0335624 2.2375617\n",
      "190 2.0304675 2.2356656\n",
      "195 2.0272236 2.2333982\n",
      "Training is complete!\n",
      "Final Training cost: 2.0245625972747803\n",
      "Final Testing cost: 2.2318248748779297\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    Y_train, Y_test = score_result[train_index], score_result[test_index]\n",
    "    \n",
    "    \n",
    "    # Define model parameters\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 200\n",
    "\n",
    "    # Define how many inputs and outputs are in our neural network\n",
    "    number_of_inputs = 500\n",
    "    number_of_outputs = 1\n",
    "\n",
    "    # Define how many neurons we want in each layer of our neural network\n",
    "    layer_1_nodes = 50\n",
    "    layer_2_nodes = 100\n",
    "    layer_3_nodes = 50\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    with tf.variable_scope('input'):\n",
    "        X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "    # Layer 1\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(\"weights1\",shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "\n",
    "    # Output Layer\n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(\"weights4\", shape=[layer_1_nodes, number_of_outputs])\n",
    "        biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        prediction = tf.matmul(layer_1_output, weights) + biases\n",
    "\n",
    "    # Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "    with tf.variable_scope('cost'):\n",
    "        Y = tf.placeholder(tf.float32)\n",
    "        cost = tf.reduce_mean(abs(prediction-Y))\n",
    "    \n",
    "    # Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize a session so that we can run TensorFlow operations\n",
    "    with tf.Session() as session:\n",
    "\n",
    "        # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Run the optimizer over and over to train the network.\n",
    "        # One epoch is one full run through the training data set.\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Feed in the training data and do one step of neural network training\n",
    "            session.run(optimizer, feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Every 5 training steps, log our progress\n",
    "            if epoch % 5 == 0:\n",
    "                training_cost = session.run(cost, feed_dict={X: X_train, Y:Y_train})\n",
    "                testing_cost = session.run(cost, feed_dict={X: X_test, Y:Y_test})\n",
    "\n",
    "                print(epoch, training_cost, testing_cost)\n",
    "\n",
    "        # Training is now complete!\n",
    "        print(\"Training is complete!\")\n",
    "\n",
    "        final_training_cost = session.run(cost, feed_dict={X: X_train, Y: Y_train})\n",
    "        final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "        print(\"Final Testing cost: {}\".format(final_testing_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.062321 6.0602183\n",
      "5 5.5669346 5.595575\n",
      "10 5.0552363 5.1093874\n",
      "15 4.5413995 4.6046963\n",
      "20 4.0413485 4.0950303\n",
      "25 3.5686922 3.6246138\n",
      "30 3.1437864 3.2121816\n",
      "35 2.7962208 2.8848507\n",
      "40 2.553022 2.6630778\n",
      "45 2.4085565 2.5366564\n",
      "50 2.330534 2.4762907\n",
      "55 2.2872834 2.4477959\n",
      "60 2.2569604 2.4284132\n",
      "65 2.2283502 2.4105759\n",
      "70 2.2004101 2.3945217\n",
      "75 2.1798089 2.3826413\n",
      "80 2.164123 2.3740633\n",
      "85 2.1521626 2.367618\n",
      "90 2.1415398 2.36214\n",
      "95 2.1327498 2.357028\n",
      "100 2.1234882 2.3523703\n",
      "105 2.116745 2.348004\n",
      "110 2.1101744 2.343452\n",
      "115 2.1029496 2.338674\n",
      "120 2.0973334 2.3335829\n",
      "125 2.091523 2.3282762\n",
      "130 2.0854359 2.3232312\n",
      "135 2.080473 2.3177183\n",
      "140 2.0758843 2.3126848\n",
      "145 2.0710387 2.3077934\n",
      "150 2.066506 2.302633\n",
      "155 2.0620923 2.2976885\n",
      "160 2.0581756 2.2925594\n",
      "165 2.054114 2.2874322\n",
      "170 2.0510647 2.282283\n",
      "175 2.0470674 2.2772973\n",
      "180 2.0432103 2.271976\n",
      "185 2.0395427 2.2668421\n",
      "190 2.0356562 2.2619812\n",
      "195 2.0326715 2.2568953\n",
      "200 2.0296624 2.2519739\n",
      "205 2.0266175 2.247082\n",
      "210 2.0233376 2.242167\n",
      "215 2.0201082 2.2373335\n",
      "220 2.0173252 2.232589\n",
      "225 2.0141754 2.22831\n",
      "230 2.011061 2.223964\n",
      "235 2.008475 2.2197325\n",
      "240 2.0058863 2.215397\n",
      "245 2.0035982 2.2111194\n",
      "250 2.001077 2.2066622\n",
      "255 1.9983191 2.202334\n",
      "260 1.9965649 2.1980445\n",
      "265 1.9944901 2.193703\n",
      "270 1.9916476 2.1895187\n",
      "275 1.9893954 2.1850965\n",
      "280 1.9869858 2.1810696\n",
      "285 1.985123 2.1771178\n",
      "290 1.983007 2.1733663\n",
      "295 1.980544 2.169393\n",
      "Training is complete!\n",
      "Final Training cost: 1.9792307615280151\n",
      "Final Testing cost: 2.166503667831421\n",
      "0 5.9911466 6.0206876\n",
      "5 5.470893 5.48928\n",
      "10 4.938597 4.950726\n",
      "15 4.414492 4.423245\n",
      "20 3.9229224 3.936662\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6e503786a93b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# Feed in the training data and do one step of neural network training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Every 5 training steps, log our progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "dropout = 0.5\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    Y_train, Y_test = score_result[train_index], score_result[test_index]\n",
    "    \n",
    "    \n",
    "    # Define model parameters\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 300\n",
    "\n",
    "    # Define how many inputs and outputs are in our neural network\n",
    "    number_of_inputs = 500\n",
    "    number_of_outputs = 1\n",
    "\n",
    "    # Define how many neurons we want in each layer of our neural network\n",
    "    layer_1_nodes = 50\n",
    "    layer_2_nodes = 100\n",
    "    layer_3_nodes = 50\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    with tf.variable_scope('input'):\n",
    "        X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "    # Layer 1\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(\"weights1\",shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "    layer_1_output = tf.layers.dropout(layer_1_output, rate=dropout)\n",
    "\n",
    "    # Output Layer\n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(\"weights4\", shape=[layer_1_nodes, number_of_outputs])\n",
    "        biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        prediction = tf.matmul(layer_1_output, weights) + biases\n",
    "    prediction = tf.layers.dropout(prediction, rate=dropout)\n",
    "    \n",
    "    \n",
    "    # Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "    with tf.variable_scope('cost'):\n",
    "        Y = tf.placeholder(tf.float32)\n",
    "        cost = tf.reduce_mean(abs(prediction-Y))\n",
    "    \n",
    "    # Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize a session so that we can run TensorFlow operations\n",
    "    with tf.Session() as session:\n",
    "\n",
    "        # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Run the optimizer over and over to train the network.\n",
    "        # One epoch is one full run through the training data set.\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Feed in the training data and do one step of neural network training\n",
    "            session.run(optimizer, feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Every 5 training steps, log our progress\n",
    "            if epoch % 5 == 0:\n",
    "                training_cost = session.run(cost, feed_dict={X: X_train, Y:Y_train})\n",
    "                testing_cost = session.run(cost, feed_dict={X: X_test, Y:Y_test})\n",
    "\n",
    "                print(epoch, training_cost, testing_cost)\n",
    "\n",
    "        # Training is now complete!\n",
    "        print(\"Training is complete!\")\n",
    "\n",
    "        final_training_cost = session.run(cost, feed_dict={X: X_train, Y: Y_train})\n",
    "        final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "        print(\"Final Testing cost: {}\".format(final_testing_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
