{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_json('cve-2002.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_json('cve-2003.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = pd.read_json('cve-2004.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3 = pd.read_json('cve-2005.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4 = pd.read_json('cve-2006.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5 = pd.read_json('cve-2007.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6 = pd.read_json('cve-2008.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset7 = pd.read_json('cve-2009.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset8 = pd.read_json('cve-2010.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset9 = pd.read_json('cve-2011.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset10 = pd.read_json('cve-2012.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset11 = pd.read_json('cve-2013.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset12 = pd.read_json('cve-2014.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset13 = pd.read_json('cve-2015.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset14 = pd.read_json('cve-2016.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset15 = pd.read_json('cve-2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset16 = pd.read_json('cve-2018.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6745, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13949, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CVE_Items', 'CVE_data_format', 'CVE_data_numberOfCVEs',\n",
       "       'CVE_data_timestamp', 'CVE_data_type', 'CVE_data_version'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset3.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurations': {'CVE_data_version': '4.0',\n",
       "  'nodes': [{'cpe': [{'cpe22Uri': 'cpe:/a:rinetd:rinetd:0.52',\n",
       "      'cpe23Uri': 'cpe:2.3:a:rinetd:rinetd:0.52:*:*:*:*:*:*:*',\n",
       "      'vulnerable': True},\n",
       "     {'cpe22Uri': 'cpe:/a:rinetd:rinetd:0.61',\n",
       "      'cpe23Uri': 'cpe:2.3:a:rinetd:rinetd:0.61:*:*:*:*:*:*:*',\n",
       "      'vulnerable': True}],\n",
       "    'operator': 'OR'}]},\n",
       " 'cve': {'CVE_data_meta': {'ASSIGNER': 'cve@mitre.org', 'ID': 'CVE-2003-0212'},\n",
       "  'affects': {'vendor': {'vendor_data': [{'product': {'product_data': [{'product_name': 'rinetd',\n",
       "         'version': {'version_data': [{'version_value': '0.52'},\n",
       "           {'version_value': '0.61'}]}}]},\n",
       "      'vendor_name': 'rinetd'}]}},\n",
       "  'data_format': 'MITRE',\n",
       "  'data_type': 'CVE',\n",
       "  'data_version': '4.0',\n",
       "  'description': {'description_data': [{'lang': 'en',\n",
       "     'value': 'handleAccept in rinetd before 0.62 does not properly resize the connection list when it becomes full and sets an array index incorrectly, which allows remote attackers to cause a denial of service and possibly execute arbitrary code via a large number of connections.'}]},\n",
       "  'problemtype': {'problemtype_data': [{'description': [{'lang': 'en',\n",
       "       'value': 'NVD-CWE-Other'}]}]},\n",
       "  'references': {'reference_data': [{'name': '20030417 Vulnerability in rinetd',\n",
       "     'refsource': 'BUGTRAQ',\n",
       "     'tags': [],\n",
       "     'url': 'http://marc.info/?l=bugtraq&m=105059298502830&w=2'},\n",
       "    {'name': 'DSA-289',\n",
       "     'refsource': 'DEBIAN',\n",
       "     'tags': ['Patch', 'Vendor Advisory'],\n",
       "     'url': 'http://www.debian.org/security/2003/dsa-289'}]}},\n",
       " 'impact': {'baseMetricV2': {'cvssV2': {'accessComplexity': 'LOW',\n",
       "    'accessVector': 'NETWORK',\n",
       "    'authentication': 'NONE',\n",
       "    'availabilityImpact': 'PARTIAL',\n",
       "    'baseScore': 7.5,\n",
       "    'confidentialityImpact': 'PARTIAL',\n",
       "    'integrityImpact': 'PARTIAL',\n",
       "    'vectorString': '(AV:N/AC:L/Au:N/C:P/I:P/A:P)',\n",
       "    'version': '2.0'},\n",
       "   'exploitabilityScore': 10.0,\n",
       "   'impactScore': 6.4,\n",
       "   'obtainAllPrivilege': False,\n",
       "   'obtainOtherPrivilege': True,\n",
       "   'obtainUserPrivilege': False,\n",
       "   'severity': 'HIGH',\n",
       "   'userInteractionRequired': False}},\n",
       " 'lastModifiedDate': '2016-10-18T02:30Z',\n",
       " 'publishedDate': '2003-05-12T04:00Z'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.CVE_Items[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=dataset.CVE_Items[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The GNU tar command, when used in FTP sessions, may allow an attacker to execute arbitrary commands.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['cve']['description']['description_data'][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['impact']['baseMetricV2'][ 'exploitabilityScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIGH'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['impact']['baseMetricV2']['severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cve', 'configurations', 'impact', 'publishedDate', 'lastModifiedDate'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = []\n",
    "j=0\n",
    "for i in range(dataset.shape[0]):\n",
    "    new=dataset.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        var=new['impact']['baseMetricV2']['severity']\n",
    "        rev.append(var)\n",
    "    else:\n",
    "        rev.append('Not Exists')\n",
    "    j=j+1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev=np.array(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6745,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HIGH'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev[330]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "val = []\n",
    "for i in range(rev.shape[0]):\n",
    "    if (rev[i] == 'Not Exists'):\n",
    "        num = num + 1\n",
    "        val.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=np.array(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = []\n",
    "severity = []\n",
    "scores = []\n",
    "\n",
    "#for i in range(dataset.shape[0]):\n",
    " #   new=dataset.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "\n",
    "#for i in range(dataset1.shape[0]):\n",
    " #   new=dataset1.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "    \n",
    "#for i in range(dataset2.shape[0]):\n",
    " #   new=dataset2.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "\n",
    "#for i in range(dataset3.shape[0]):\n",
    " #   new=dataset3.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "\n",
    "#for i in range(dataset4.shape[0]):\n",
    " #   new=dataset4.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset5.shape[0]):\n",
    " #   new=dataset5.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset6.shape[0]):\n",
    " #   new=dataset6.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset2.shape[0]):\n",
    " #   new=dataset2.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset7.shape[0]):\n",
    " #   new=dataset7.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset8.shape[0]):\n",
    " #   new=dataset8.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset9.shape[0]):\n",
    " #   new=dataset9.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset10.shape[0]):\n",
    " #   new=dataset10.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset11.shape[0]):\n",
    " #   new=dataset11.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset12.shape[0]):\n",
    " #   new=dataset12.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset13.shape[0]):\n",
    "   # new=dataset13.CVE_Items[i]\n",
    "    #if('baseMetricV2' in new['impact'].keys()):\n",
    "        #severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        #scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        #description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "#for i in range(dataset14.shape[0]):\n",
    " #   new=dataset14.CVE_Items[i]\n",
    "  #  if('baseMetricV2' in new['impact'].keys()):\n",
    "   #     severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "    #    scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "     #   description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "for i in range(dataset15.shape[0]):\n",
    "    new=dataset15.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])\n",
    "        \n",
    "for i in range(dataset16.shape[0]):\n",
    "    new=dataset16.CVE_Items[i]\n",
    "    if('baseMetricV2' in new['impact'].keys()):\n",
    "        severity.append(new['impact']['baseMetricV2']['severity'])\n",
    "        scores.append(new['impact']['baseMetricV2']['cvssV2']['baseScore'])\n",
    "        description.append(new['cve']['description']['description_data'][0]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = np.array(description)\n",
    "severity = np.array(severity)\n",
    "scores = np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24281,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24281,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "severity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24281,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft Windows 10 Gold, Windows 10 1511, Windows 10 1607, and Windows Server 2016 allow an attacker to exploit a security feature bypass vulnerability in Device Guard that could allow the attacker to inject malicious code into a Windows PowerShell session, aka \"Device Guard Code Integrity Policy Security Feature Bypass Vulnerability.\" This CVE ID is unique from CVE-2017-0173, CVE-2017-0215, CVE-2017-0216, and CVE-2017-0218.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MEDIUM'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "severity[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of reviews based on the dataframe column size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_description = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length\n",
    "# of the movie review list \n",
    "for i in range(description.shape[0]):\n",
    "    # Call our function for each one, and add the result to the list of\n",
    "    # clean reviews\n",
    "    clean_description.append( review_to_words( description[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'microsoft windows gold windows windows windows server allow attacker exploit security feature bypass vulnerability device guard could allow attacker inject malicious code windows powershell session aka device guard code integrity policy security feature bypass vulnerability cve id unique cve cve cve cve'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_description[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_description_array = np.array(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating the bag of words...\\n\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 500) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "description_features = vectorizer.fit_transform(clean_description_array)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "description_features = description_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24281, 500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982297241663236\n",
      "0.992998352553542\n",
      "0.984349258649094\n",
      "0.9892915980230642\n",
      "0.9936148300720906\n",
      "avg 0.9885102561922053\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "n_folds = 5\n",
    "score = 0.0\n",
    "skf = StratifiedKFold(severity, n_folds)\n",
    "avg_score = 0\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = severity[train_index], severity[test_index]\n",
    "    forest = RandomForestClassifier(n_estimators = 50)\n",
    "    forest.fit( X_train, y_train )\n",
    "    score = forest.score(X_test,y_test)\n",
    "    avg_score += score \n",
    "    print(score)\n",
    "    \n",
    "print(\"avg\",avg_score/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24281"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_result = np.array(scores).astype(np.float)\n",
    "score_result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9474\n",
      "MAE: 0.8387\n",
      "MAE: 0.8164\n",
      "MAE: 0.8271\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-dc75b35e151a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m           'learning_rate': 0.01, 'loss': 'ls'}\n\u001b[1;32m     15\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "    params = {'n_estimators': 500, 'max_depth': 8, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.9656\n",
      "MAE: 0.9153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-718d89303280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "    params = {'n_estimators': 500, 'max_depth': 8, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    clf = ensemble.GradientBoostingRegressor(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "19398/19398 [==============================] - 3s 133us/step - loss: 1.0922\n",
      "Epoch 2/22\n",
      "19398/19398 [==============================] - 2s 119us/step - loss: 0.8277\n",
      "Epoch 3/22\n",
      "19398/19398 [==============================] - 2s 121us/step - loss: 0.7610\n",
      "Epoch 4/22\n",
      "19398/19398 [==============================] - 2s 119us/step - loss: 0.7158\n",
      "Epoch 5/22\n",
      "19398/19398 [==============================] - 2s 120us/step - loss: 0.6745\n",
      "Epoch 6/22\n",
      "19398/19398 [==============================] - 2s 120us/step - loss: 0.6394\n",
      "Epoch 7/22\n",
      "19398/19398 [==============================] - 2s 121us/step - loss: 0.6154\n",
      "Epoch 8/22\n",
      "19398/19398 [==============================] - 2s 122us/step - loss: 0.5911\n",
      "Epoch 9/22\n",
      "19398/19398 [==============================] - 2s 123us/step - loss: 0.5683\n",
      "Epoch 10/22\n",
      "19398/19398 [==============================] - 2s 123us/step - loss: 0.5525\n",
      "Epoch 11/22\n",
      "19398/19398 [==============================] - 3s 130us/step - loss: 0.5334\n",
      "Epoch 12/22\n",
      "19398/19398 [==============================] - 3s 146us/step - loss: 0.5198\n",
      "Epoch 13/22\n",
      "19398/19398 [==============================] - 3s 142us/step - loss: 0.5065\n",
      "Epoch 14/22\n",
      "19398/19398 [==============================] - 3s 134us/step - loss: 0.4937\n",
      "Epoch 15/22\n",
      "19398/19398 [==============================] - 3s 134us/step - loss: 0.4804\n",
      "Epoch 16/22\n",
      "19398/19398 [==============================] - 2s 128us/step - loss: 0.4721\n",
      "Epoch 17/22\n",
      "19398/19398 [==============================] - 2s 125us/step - loss: 0.4597\n",
      "Epoch 18/22\n",
      "19398/19398 [==============================] - 2s 127us/step - loss: 0.4515\n",
      "Epoch 19/22\n",
      "19398/19398 [==============================] - 2s 127us/step - loss: 0.4459\n",
      "Epoch 20/22\n",
      "19398/19398 [==============================] - 2s 122us/step - loss: 0.4370\n",
      "Epoch 21/22\n",
      "19398/19398 [==============================] - 2s 122us/step - loss: 0.4280\n",
      "Epoch 22/22\n",
      "19398/19398 [==============================] - 3s 131us/step - loss: 0.4250\n",
      "MAE: 0.7809\n",
      "Epoch 1/22\n",
      "19412/19412 [==============================] - 3s 141us/step - loss: 1.1087\n",
      "Epoch 2/22\n",
      "19412/19412 [==============================] - 2s 123us/step - loss: 0.8424\n",
      "Epoch 3/22\n",
      "19412/19412 [==============================] - 2s 122us/step - loss: 0.7788\n",
      "Epoch 4/22\n",
      "19412/19412 [==============================] - 2s 124us/step - loss: 0.7261\n",
      "Epoch 5/22\n",
      "19412/19412 [==============================] - 2s 124us/step - loss: 0.6932\n",
      "Epoch 6/22\n",
      "19412/19412 [==============================] - 2s 129us/step - loss: 0.6595\n",
      "Epoch 7/22\n",
      "19412/19412 [==============================] - 2s 128us/step - loss: 0.6353\n",
      "Epoch 8/22\n",
      "19412/19412 [==============================] - 3s 130us/step - loss: 0.6109\n",
      "Epoch 9/22\n",
      "19412/19412 [==============================] - 3s 129us/step - loss: 0.5932\n",
      "Epoch 10/22\n",
      "19412/19412 [==============================] - 2s 126us/step - loss: 0.5719\n",
      "Epoch 11/22\n",
      "19412/19412 [==============================] - 3s 135us/step - loss: 0.5569\n",
      "Epoch 12/22\n",
      "19412/19412 [==============================] - 3s 136us/step - loss: 0.5421\n",
      "Epoch 13/22\n",
      "19412/19412 [==============================] - 3s 135us/step - loss: 0.5262\n",
      "Epoch 14/22\n",
      "19412/19412 [==============================] - 2s 127us/step - loss: 0.5148\n",
      "Epoch 15/22\n",
      "19412/19412 [==============================] - 3s 146us/step - loss: 0.5038\n",
      "Epoch 16/22\n",
      "19412/19412 [==============================] - 3s 131us/step - loss: 0.4914\n",
      "Epoch 17/22\n",
      "19412/19412 [==============================] - 3s 129us/step - loss: 0.4818\n",
      "Epoch 18/22\n",
      "19412/19412 [==============================] - 2s 127us/step - loss: 0.4697\n",
      "Epoch 19/22\n",
      "19412/19412 [==============================] - 3s 138us/step - loss: 0.4644\n",
      "Epoch 20/22\n",
      "19412/19412 [==============================] - 3s 129us/step - loss: 0.4523\n",
      "Epoch 21/22\n",
      "19412/19412 [==============================] - 3s 132us/step - loss: 0.4444 0s - los\n",
      "Epoch 22/22\n",
      "19412/19412 [==============================] - 3s 130us/step - loss: 0.4401\n",
      "MAE: 0.6019\n",
      "Epoch 1/22\n",
      "19429/19429 [==============================] - 3s 147us/step - loss: 1.0852\n",
      "Epoch 2/22\n",
      "19429/19429 [==============================] - 3s 133us/step - loss: 0.8219\n",
      "Epoch 3/22\n",
      "19429/19429 [==============================] - 3s 133us/step - loss: 0.7526\n",
      "Epoch 4/22\n",
      "19429/19429 [==============================] - 3s 134us/step - loss: 0.7065\n",
      "Epoch 5/22\n",
      "19429/19429 [==============================] - 3s 151us/step - loss: 0.6656\n",
      "Epoch 6/22\n",
      "19429/19429 [==============================] - 3s 139us/step - loss: 0.6363\n",
      "Epoch 7/22\n",
      "19429/19429 [==============================] - 2s 127us/step - loss: 0.6116\n",
      "Epoch 8/22\n",
      "19429/19429 [==============================] - 3s 129us/step - loss: 0.5858\n",
      "Epoch 9/22\n",
      "19429/19429 [==============================] - 2s 121us/step - loss: 0.5663\n",
      "Epoch 10/22\n",
      "19429/19429 [==============================] - 2s 121us/step - loss: 0.5480\n",
      "Epoch 11/22\n",
      "19429/19429 [==============================] - 2s 122us/step - loss: 0.5316\n",
      "Epoch 12/22\n",
      "19429/19429 [==============================] - 2s 124us/step - loss: 0.5197\n",
      "Epoch 13/22\n",
      "19429/19429 [==============================] - 2s 122us/step - loss: 0.5043\n",
      "Epoch 14/22\n",
      "19429/19429 [==============================] - 2s 124us/step - loss: 0.4900\n",
      "Epoch 15/22\n",
      "19429/19429 [==============================] - 2s 121us/step - loss: 0.4815\n",
      "Epoch 16/22\n",
      "19429/19429 [==============================] - 2s 122us/step - loss: 0.4674\n",
      "Epoch 17/22\n",
      "19429/19429 [==============================] - 2s 121us/step - loss: 0.4583\n",
      "Epoch 18/22\n",
      "19429/19429 [==============================] - 2s 124us/step - loss: 0.4500\n",
      "Epoch 19/22\n",
      "19429/19429 [==============================] - 2s 121us/step - loss: 0.4395\n",
      "Epoch 20/22\n",
      "19429/19429 [==============================] - 2s 120us/step - loss: 0.4325\n",
      "Epoch 21/22\n",
      "19429/19429 [==============================] - 2s 122us/step - loss: 0.4284\n",
      "Epoch 22/22\n",
      "19429/19429 [==============================] - 2s 123us/step - loss: 0.4186 0s - \n",
      "MAE: 0.7636\n",
      "Epoch 1/22\n",
      "19436/19436 [==============================] - 3s 143us/step - loss: 1.1179\n",
      "Epoch 2/22\n",
      "19436/19436 [==============================] - 2s 128us/step - loss: 0.8267\n",
      "Epoch 3/22\n",
      "19436/19436 [==============================] - 2s 120us/step - loss: 0.7604\n",
      "Epoch 4/22\n",
      "19436/19436 [==============================] - 2s 121us/step - loss: 0.7100\n",
      "Epoch 5/22\n",
      "19436/19436 [==============================] - 2s 120us/step - loss: 0.6743\n",
      "Epoch 6/22\n",
      "19436/19436 [==============================] - 2s 119us/step - loss: 0.6419\n",
      "Epoch 7/22\n",
      "19436/19436 [==============================] - 2s 119us/step - loss: 0.6184\n",
      "Epoch 8/22\n",
      "19436/19436 [==============================] - 2s 121us/step - loss: 0.5918\n",
      "Epoch 9/22\n",
      "19436/19436 [==============================] - 3s 133us/step - loss: 0.5756\n",
      "Epoch 10/22\n",
      "19436/19436 [==============================] - 3s 134us/step - loss: 0.5529\n",
      "Epoch 11/22\n",
      "19436/19436 [==============================] - 3s 130us/step - loss: 0.5348\n",
      "Epoch 12/22\n",
      "19436/19436 [==============================] - 3s 133us/step - loss: 0.5232\n",
      "Epoch 13/22\n",
      "19436/19436 [==============================] - 2s 128us/step - loss: 0.5085\n",
      "Epoch 14/22\n",
      "19436/19436 [==============================] - 2s 126us/step - loss: 0.4957\n",
      "Epoch 15/22\n",
      "19436/19436 [==============================] - 2s 126us/step - loss: 0.4856\n",
      "Epoch 16/22\n",
      "19436/19436 [==============================] - 2s 128us/step - loss: 0.4730\n",
      "Epoch 17/22\n",
      "19436/19436 [==============================] - 2s 125us/step - loss: 0.4619\n",
      "Epoch 18/22\n",
      "19436/19436 [==============================] - 2s 125us/step - loss: 0.4528\n",
      "Epoch 19/22\n",
      "19436/19436 [==============================] - 2s 127us/step - loss: 0.4449\n",
      "Epoch 20/22\n",
      "19436/19436 [==============================] - 2s 127us/step - loss: 0.4374\n",
      "Epoch 21/22\n",
      "19436/19436 [==============================] - 2s 127us/step - loss: 0.4302\n",
      "Epoch 22/22\n",
      "19436/19436 [==============================] - 3s 130us/step - loss: 0.4222\n",
      "MAE: 0.6693\n",
      "Epoch 1/22\n",
      "19449/19449 [==============================] - 3s 151us/step - loss: 1.0893\n",
      "Epoch 2/22\n",
      "19449/19449 [==============================] - 3s 140us/step - loss: 0.8148\n",
      "Epoch 3/22\n",
      "19449/19449 [==============================] - 2s 126us/step - loss: 0.7473\n",
      "Epoch 4/22\n",
      "19449/19449 [==============================] - 3s 138us/step - loss: 0.7003\n",
      "Epoch 5/22\n",
      "19449/19449 [==============================] - 2s 120us/step - loss: 0.6668\n",
      "Epoch 6/22\n",
      "19449/19449 [==============================] - 2s 123us/step - loss: 0.6390\n",
      "Epoch 7/22\n",
      "19449/19449 [==============================] - 2s 117us/step - loss: 0.6141\n",
      "Epoch 8/22\n",
      "19449/19449 [==============================] - 3s 147us/step - loss: 0.5918\n",
      "Epoch 9/22\n",
      "19449/19449 [==============================] - 3s 135us/step - loss: 0.5702\n",
      "Epoch 10/22\n",
      "19449/19449 [==============================] - 3s 142us/step - loss: 0.5554\n",
      "Epoch 11/22\n",
      "19449/19449 [==============================] - 2s 128us/step - loss: 0.5392\n",
      "Epoch 12/22\n",
      "19449/19449 [==============================] - 2s 127us/step - loss: 0.5247\n",
      "Epoch 13/22\n",
      "19449/19449 [==============================] - 2s 128us/step - loss: 0.5140\n",
      "Epoch 14/22\n",
      "19449/19449 [==============================] - 3s 143us/step - loss: 0.5032\n",
      "Epoch 15/22\n",
      "19449/19449 [==============================] - 3s 136us/step - loss: 0.4891\n",
      "Epoch 16/22\n",
      "19449/19449 [==============================] - 3s 133us/step - loss: 0.4785\n",
      "Epoch 17/22\n",
      "19449/19449 [==============================] - 3s 134us/step - loss: 0.4708\n",
      "Epoch 18/22\n",
      "19449/19449 [==============================] - 3s 132us/step - loss: 0.4602\n",
      "Epoch 19/22\n",
      "19449/19449 [==============================] - 3s 135us/step - loss: 0.4559\n",
      "Epoch 20/22\n",
      "19449/19449 [==============================] - 2s 125us/step - loss: 0.4475\n",
      "Epoch 21/22\n",
      "19449/19449 [==============================] - 3s 130us/step - loss: 0.4415\n",
      "Epoch 22/22\n",
      "19449/19449 [==============================] - 3s 141us/step - loss: 0.4304\n",
      "MAE: 0.7607\n",
      "avg 0.7152773262031636\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # Initialising the ANN\n",
    "    model1 = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    model1.add(Dense(32, activation = 'relu', input_dim = 500))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model1.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "    # Adding the third hidden layer\n",
    "    model1.add(Dense(units = 32, activation = 'relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "\n",
    "    model1.add(Dense(units = 1))\n",
    "\n",
    "    #model.add(Dense(1))\n",
    "    # Compiling the ANN\n",
    "    model1.compile(optimizer = 'sgd', loss = 'mean_absolute_error')\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "    model1.fit(X_train, y_train, batch_size = 10, epochs = 22, shuffle = True)\n",
    "\n",
    "    mad1 = mean_squared_error(y_test, model1.predict(X_test))\n",
    "    avg_mad += mad1\n",
    "    print(\"MAE: %.4f\" % mad1)\n",
    "print(\"avg\",avg_mad/n_folds)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.layers import Conv2D \n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "  \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    \n",
    "    # Initialising the ANN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), input_shape=(X_train.shape[0],500,1), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(3))\n",
    "    # Compiling the ANN\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_absolute_error')\n",
    "    \n",
    "    \n",
    "    X_train.resize((1,X_train.shape[0],X_train.shape[1],1))\n",
    "    y_train.resize((1,y_train.shape[0],500,1))\n",
    "    # Fitting the ANN to the Training set\n",
    "    model.fit(X_train, y_train, batch_size = 10, epochs = 20, shuffle = True,validation_data=(X_train,y_train))\n",
    "\n",
    "    mad = mean_squared_error(y_test, model.predict(X_test))\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[6.3652406 6.3652406 6.3652406 ... 6.4652405 4.2652407 4.2652407]\n",
      " [6.3652406 6.3652406 6.3652406 ... 6.4652405 4.2652407 4.2652407]\n",
      " [6.380944  6.380944  6.380944  ... 6.4809437 4.280944  4.280944 ]\n",
      " ...\n",
      " [6.3446207 6.3446207 6.3446207 ... 6.4446206 4.244621  4.244621 ]\n",
      " [6.4085917 6.4085917 6.4085917 ... 6.5085917 4.308592  4.308592 ]\n",
      " [6.454924  6.454924  6.454924  ... 6.554924  4.354924  4.354924 ]] [[7.5131545 9.213155  4.213155  ... 7.8131547 2.2131546 3.6131546]\n",
      " [7.4333844 9.133385  4.1333847 ... 7.7333846 2.1333842 3.5333843]\n",
      " [7.465279  9.165279  4.1652794 ... 7.7652793 2.1652794 3.5652795]\n",
      " ...\n",
      " [7.5428405 9.242841  4.242841  ... 7.8428407 2.2428405 3.6428406]\n",
      " [7.633146  9.333146  4.333146  ... 7.933146  2.333146  3.7331462]\n",
      " [7.557093  9.257093  4.2570934 ... 7.8570933 2.2570934 3.6570935]]\n",
      "5 [[5.7015676 5.7015676 5.7015676 ... 5.8015676 3.6015677 3.6015677]\n",
      " [5.7015676 5.7015676 5.7015676 ... 5.8015676 3.6015677 3.6015677]\n",
      " [5.8632126 5.8632126 5.8632126 ... 5.9632125 3.763213  3.763213 ]\n",
      " ...\n",
      " [5.4887166 5.4887166 5.4887166 ... 5.5887165 3.3887167 3.3887167]\n",
      " [6.0418596 6.0418596 6.0418596 ... 6.1418595 3.9418597 3.9418597]\n",
      " [6.049436  6.049436  6.049436  ... 6.149436  3.9494362 3.9494362]] [[7.030766  8.730766  3.7307663 ... 7.330766  1.730766  3.1307662]\n",
      " [7.009295  8.709295  3.7092953 ... 7.309295  1.709295  3.1092951]\n",
      " [7.0076895 8.70769   3.70769   ... 7.3076897 1.7076898 3.1076899]\n",
      " ...\n",
      " [7.152955  8.852955  3.8529553 ... 7.4529552 1.8529551 3.2529552]\n",
      " [7.1467524 8.846752  3.8467524 ... 7.4467525 1.8467523 3.2467523]\n",
      " [7.1746054 8.874606  3.8746057 ... 7.4746056 1.8746054 3.2746055]]\n",
      "10 [[4.7599487 4.7599487 4.7599487 ... 4.8599486 2.6599488 2.6599488]\n",
      " [4.7599487 4.7599487 4.7599487 ... 4.8599486 2.6599488 2.6599488]\n",
      " [5.220437  5.220437  5.220437  ... 5.320437  3.1204371 3.1204371]\n",
      " ...\n",
      " [4.4238844 4.4238844 4.4238844 ... 4.5238843 2.3238845 2.3238845]\n",
      " [5.5685964 5.5685964 5.5685964 ... 5.6685963 3.4685965 3.4685965]\n",
      " [5.528598  5.528598  5.528598  ... 5.6285973 3.4285977 3.4285977]] [[6.201638  7.9016385 2.9016385 ... 6.5016384 0.9016384 2.3016386]\n",
      " [6.283187  7.983187  2.9831872 ... 6.583187  0.9831871 2.3831873]\n",
      " [6.1843405 7.8843403 2.8843405 ... 6.4843407 0.8843403 2.2843404]\n",
      " ...\n",
      " [6.5750113 8.275011  3.2750115 ... 6.8750114 1.2750112 2.6750112]\n",
      " [6.4794555 8.179456  3.1794558 ... 6.7794557 1.1794555 2.5794556]\n",
      " [6.4031477 8.1031475 3.103148  ... 6.703148  1.1031476 2.5031476]]\n",
      "15 [[3.2562237 3.2562237 3.2562237 ... 3.3562236 1.1562238 1.1562238]\n",
      " [3.2562237 3.2562237 3.2562237 ... 3.3562236 1.1562238 1.1562238]\n",
      " [4.0808506 4.0808506 4.0808506 ... 4.180851  1.9808509 1.9808509]\n",
      " ...\n",
      " [2.6997554 2.6997554 2.6997554 ... 2.7997553 0.5997555 0.5997555]\n",
      " [4.823404  4.823404  4.823404  ... 4.9234037 2.723404  2.723404 ]\n",
      " [4.7103925 4.7103925 4.7103925 ... 4.8103924 2.6103926 2.6103926]] [[4.8050485  6.5050488  1.5050488  ... 5.1050487  0.4949515  0.9050486 ]\n",
      " [5.027257   6.7272577  1.7272575  ... 5.327257   0.27274275 1.1272573 ]\n",
      " [4.9376698  6.63767    1.63767    ... 5.23767    0.3623302  1.0376699 ]\n",
      " ...\n",
      " [5.6468854  7.3468857  2.3468857  ... 5.9468856  0.34688544 1.7468855 ]\n",
      " [5.3507447  7.050745   2.050745   ... 5.650745   0.05074477 1.4507449 ]\n",
      " [5.0048313  6.704832   1.7048318  ... 5.3048315  0.2951684  1.1048317 ]]\n",
      "20 [[0.9386878  0.9386878  0.9386878  ... 1.0386877  1.1613121  1.1613121 ]\n",
      " [0.9386878  0.9386878  0.9386878  ... 1.0386877  1.1613121  1.1613121 ]\n",
      " [2.16775    2.16775    2.16775    ... 2.2677498  0.06774998 0.06774998]\n",
      " ...\n",
      " [0.1315341  0.1315341  0.1315341  ... 0.03153419 2.231534   2.231534  ]\n",
      " [3.6610157  3.6610157  3.6610157  ... 3.7610157  1.5610158  1.5610158 ]\n",
      " [3.4907637  3.4907637  3.4907637  ... 3.5907636  1.3907638  1.3907638 ]] [[2.6008186  4.300819   0.6991811  ... 2.9008188  2.6991813  1.2991812 ]\n",
      " [3.1145139  4.814514   0.18548584 ... 3.414514   2.185486   0.785486  ]\n",
      " [2.96796    4.66796    0.33203983 ... 3.26796    2.33204    0.93204   ]\n",
      " ...\n",
      " [4.127846   5.8278465  0.8278463  ... 4.427846   1.172154   0.22784615]\n",
      " [3.4660645  5.1660647  0.16606474 ... 3.7660646  1.8339355  0.4339354 ]\n",
      " [2.750214   4.4502144  0.5497856  ... 3.0502143  2.5497859  1.1497858 ]]\n",
      "25 [[1.144319   1.144319   1.144319   ... 1.0443192  3.244319   3.244319  ]\n",
      " [1.144319   1.144319   1.144319   ... 1.0443192  3.244319   3.244319  ]\n",
      " [0.25361538 0.25361538 0.25361538 ... 0.35361528 1.8463845  1.8463845 ]\n",
      " ...\n",
      " [2.7296157  2.7296157  2.7296157  ... 2.6296158  4.8296156  4.8296156 ]\n",
      " [2.5121317  2.5121317  2.5121317  ... 2.6121316  0.4121318  0.4121318 ]\n",
      " [2.236896   2.236896   2.236896   ... 2.336896   0.13689613 0.13689613]] [[0.57021713 2.2702174  2.7297826  ... 0.8702173  4.729783   3.3297827 ]\n",
      " [1.3488545  3.0488548  1.9511452  ... 1.6488547  3.9511454  2.5511453 ]\n",
      " [1.1218119  2.8218122  2.1781878  ... 1.421812   4.1781883  2.778188  ]\n",
      " ...\n",
      " [2.7323031  4.4323034  0.5676966  ... 3.0323033  2.5676968  1.1676967 ]\n",
      " [1.5124817  3.212482   1.787518   ... 1.8124819  3.7875183  2.3875182 ]\n",
      " [0.51106024 2.2110605  2.7889395  ... 0.8110604  4.7889395  3.3889396 ]]\n",
      "30 [[0.6877928  0.6877928  0.6877928  ... 0.5877929  2.7877927  2.7877927 ]\n",
      " [0.6877928  0.6877928  0.6877928  ... 0.5877929  2.7877927  2.7877927 ]\n",
      " [0.28702354 0.28702354 0.28702354 ... 0.38702345 1.8129764  1.8129764 ]\n",
      " ...\n",
      " [2.264834   2.264834   2.264834   ... 2.164834   4.364834   4.364834  ]\n",
      " [2.616088   2.616088   2.616088   ... 2.7160878  0.516088   0.516088  ]\n",
      " [2.2185202  2.2185202  2.2185202  ... 2.31852    0.11852026 0.11852026]] [[1.0003834  2.7003837  2.2996163  ... 1.3003836  4.299617   2.8996165 ]\n",
      " [1.637886   3.3378863  1.6621137  ... 1.9378862  3.662114   2.2621138 ]\n",
      " [1.3605552  3.0605555  1.9394445  ... 1.6605554  3.9394448  2.5394447 ]\n",
      " ...\n",
      " [2.986957   4.6869574  0.31304264 ... 3.2869573  2.3130429  0.9130428 ]\n",
      " [1.5666904  3.2666907  1.7333093  ... 1.8666906  3.7333095  2.3333094 ]\n",
      " [0.70326805 2.4032683  2.5967317  ... 1.0032682  4.596732   3.1967318 ]]\n",
      "35 [[0.57410955 0.57410955 0.57410955 ... 0.67410946 1.5258904  1.5258904 ]\n",
      " [0.57410955 0.57410955 0.57410955 ... 0.67410946 1.5258904  1.5258904 ]\n",
      " [1.073854   1.073854   1.073854   ... 1.1738539  1.0261459  1.0261459 ]\n",
      " ...\n",
      " [0.7799363  0.7799363  0.7799363  ... 0.6799364  2.8799362  2.8799362 ]\n",
      " [3.1824996  3.1824996  3.1824996  ... 3.2824996  1.0824997  1.0824997 ]\n",
      " [2.7082143  2.7082143  2.7082143  ... 2.8082142  0.6082144  0.6082144 ]] [[2.2159696  3.9159698  1.0840302  ... 2.5159698  3.0840304  1.6840303 ]\n",
      " [2.580769   4.2807693  0.71923065 ... 2.8807693  2.719231   1.3192308 ]\n",
      " [2.3209481  4.0209484  0.9790516  ... 2.6209483  2.9790518  1.5790517 ]\n",
      " ...\n",
      " [3.7847977  5.484798   0.48479795 ... 4.084798   1.5152023  0.11520219]\n",
      " [2.4058695  4.10587    0.89413023 ... 2.7058697  2.8941305  1.4941304 ]\n",
      " [1.7959414  3.4959416  1.5040584  ... 2.0959415  3.5040586  2.1040585 ]]\n",
      "40 [[1.0635366  1.0635366  1.0635366  ... 1.1635365  1.0364633  1.0364633 ]\n",
      " [1.0635366  1.0635366  1.0635366  ... 1.1635365  1.0364633  1.0364633 ]\n",
      " [1.2901945  1.2901945  1.2901945  ... 1.3901944  0.8098054  0.8098054 ]\n",
      " ...\n",
      " [0.20345688 0.20345688 0.20345688 ... 0.10345697 2.3034568  2.3034568 ]\n",
      " [3.4041433  3.4041433  3.4041433  ... 3.5041432  1.3041434  1.3041434 ]\n",
      " [2.8330238  2.8330238  2.8330238  ... 2.9330237  0.7330239  0.7330239 ]] [[2.7259145  4.425915   0.57408524 ... 3.0259147  2.5740855  1.1740854 ]\n",
      " [2.9354658  4.635466   0.3645339  ... 3.235466   2.3645341  0.96453404]\n",
      " [2.6983056  4.398306   0.6016941  ... 2.9983058  2.6016943  1.2016943 ]\n",
      " ...\n",
      " [4.1329775  5.832978   0.8329778  ... 4.4329777  1.1670225  0.23297763]\n",
      " [2.6370769  4.337077   0.66292286 ... 2.937077   2.662923   1.262923  ]\n",
      " [2.161162   3.8611622  1.1388378  ... 2.461162   3.138838   1.738838  ]]\n",
      "45 [[0.6974435  0.6974435  0.6974435  ... 0.7974434  1.4025564  1.4025564 ]\n",
      " [0.6974435  0.6974435  0.6974435  ... 0.7974434  1.4025564  1.4025564 ]\n",
      " [0.82782316 0.82782316 0.82782316 ... 0.92782307 1.2721767  1.2721767 ]\n",
      " ...\n",
      " [0.66723204 0.66723204 0.66723204 ... 0.56723213 2.767232   2.767232  ]\n",
      " [3.2122488  3.2122488  3.2122488  ... 3.3122487  1.1122489  1.1122489 ]\n",
      " [2.5236182  2.5236182  2.5236182  ... 2.6236181  0.42361832 0.42361832]] [[2.5008864  4.2008867  0.7991133  ... 2.8008866  2.7991135  1.3991134 ]\n",
      " [2.6146936  4.314694   0.6853061  ... 2.9146938  2.6853063  1.2853062 ]\n",
      " [2.368451   4.0684514  0.9315486  ... 2.6684513  2.9315488  1.5315487 ]\n",
      " ...\n",
      " [3.9432693  5.6432695  0.64326954 ... 4.2432694  1.3567307  0.0432694 ]\n",
      " [2.1611462  3.8611465  1.1388535  ... 2.4611464  3.1388538  1.7388537 ]\n",
      " [1.6259079  3.3259082  1.6740918  ... 1.9259081  3.674092   2.274092  ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 [[0.1427002  0.1427002  0.1427002  ... 0.2427001  1.9572997  1.9572997 ]\n",
      " [0.1427002  0.1427002  0.1427002  ... 0.2427001  1.9572997  1.9572997 ]\n",
      " [0.25236702 0.25236702 0.25236702 ... 0.35236692 1.8476329  1.8476329 ]\n",
      " ...\n",
      " [1.3483019  1.3483019  1.3483019  ... 1.248302   3.4483018  3.4483018 ]\n",
      " [2.9552727  2.9552727  2.9552727  ... 3.0552726  0.85527277 0.85527277]\n",
      " [2.138188   2.138188   2.138188   ... 2.2381878  0.03818798 0.03818798]] [[2.105001   3.8050013  1.1949987  ... 2.4050012  3.194999   1.7949989 ]\n",
      " [2.1241922  3.8241925  1.1758075  ... 2.4241924  3.1758077  1.7758076 ]\n",
      " [1.8947768  3.594777   1.4052229  ... 2.194777   3.4052231  2.005223  ]\n",
      " ...\n",
      " [3.6612616  5.361262   0.36126184 ... 3.9612617  1.6387384  0.2387383 ]\n",
      " [1.5516386  3.251639   1.7483611  ... 1.8516388  3.7483613  2.3483613 ]\n",
      " [0.90448475 2.604485   2.395515   ... 1.2044849  4.3955154  2.995515  ]]\n",
      "55 [[0.09928226 0.09928226 0.09928226 ... 0.19928217 2.0007176  2.0007176 ]\n",
      " [0.09928226 0.09928226 0.09928226 ... 0.19928217 2.0007176  2.0007176 ]\n",
      " [0.20220089 0.20220089 0.20220089 ... 0.3022008  1.897799   1.897799  ]\n",
      " ...\n",
      " [1.3489718  1.3489718  1.3489718  ... 1.2489719  3.4489717  3.4489717 ]\n",
      " [2.9981039  2.9981039  2.9981039  ... 3.0981038  0.89810395 0.89810395]\n",
      " [2.1200476  2.1200476  2.1200476  ... 2.2200475  0.02004766 0.02004766]] [[2.1611624  3.8611627  1.1388373  ... 2.4611626  3.1388376  1.7388375 ]\n",
      " [2.0818892  3.7818894  1.2181106  ... 2.3818893  3.2181108  1.8181107 ]\n",
      " [1.8722277  3.572228   1.427772   ... 2.1722279  3.4277723  2.0277722 ]\n",
      " ...\n",
      " [3.7254524  5.4254527  0.4254527  ... 4.0254526  1.5745475  0.17454743]\n",
      " [1.4746342  3.1746345  1.8253655  ... 1.7746344  3.8253658  2.4253657 ]\n",
      " [0.85037327 2.5503736  2.4496264  ... 1.1503735  4.449627   3.0496266 ]]\n",
      "60 [[0.41267586 0.41267586 0.41267586 ... 0.51267576 1.687324   1.687324  ]\n",
      " [0.41267586 0.41267586 0.41267586 ... 0.51267576 1.687324   1.687324  ]\n",
      " [0.5163398  0.5163398  0.5163398  ... 0.6163397  1.5836601  1.5836601 ]\n",
      " ...\n",
      " [0.90994406 0.90994406 0.90994406 ... 0.80994415 3.009944   3.009944  ]\n",
      " [3.2246335  3.2246335  3.2246335  ... 3.3246334  1.1246336  1.1246336 ]\n",
      " [2.3514838  2.3514838  2.3514838  ... 2.4514837  0.25148392 0.25148392]] [[2.501657   4.2016573  0.7983427  ... 2.8016572  2.798343   1.3983428 ]\n",
      " [2.345591   4.0455914  0.95440865 ... 2.6455913  2.954409   1.5544088 ]\n",
      " [2.1667728  3.8667731  1.1332269  ... 2.466773   3.133227   1.733227  ]\n",
      " ...\n",
      " [3.9945557  5.694556   0.694556   ... 4.2945557  1.3054442  0.09455585]\n",
      " [1.7658129  3.4658132  1.5341868  ... 2.065813   3.534187   2.134187  ]\n",
      " [1.253993   2.9539933  2.0460067  ... 1.5539932  4.046007   2.6460068 ]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-34e0bdca56d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# Feed in the training data and do one step of neural network training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;31m# Every 5 training steps, log our progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    Y_train, Y_test = score_result[train_index], score_result[test_index]\n",
    "    \n",
    "    \n",
    "    # Define model parameters\n",
    "    learning_rate = 0.001\n",
    "    training_epochs = 500\n",
    "\n",
    "    # Define how many inputs and outputs are in our neural network\n",
    "    number_of_inputs = 500\n",
    "    number_of_outputs = 1\n",
    "\n",
    "    # Define how many neurons we want in each layer of our neural network\n",
    "    layer_1_nodes = 50\n",
    "    layer_2_nodes = 100\n",
    "    layer_3_nodes = 50\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Input Layer\n",
    "    with tf.variable_scope('input'):\n",
    "        X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))\n",
    "\n",
    "    # Layer 1\n",
    "    with tf.variable_scope('layer_1'):\n",
    "        weights = tf.get_variable(\"weights1\", shape=[number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases1\", shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
    "\n",
    "    # Layer 2\n",
    "    with tf.variable_scope('layer_2'):\n",
    "        weights = tf.get_variable(\"weights2\", shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases2\", shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
    "\n",
    "    # Layer 3\n",
    "    with tf.variable_scope('layer_3'):\n",
    "        weights = tf.get_variable(\"weights3\", shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        biases = tf.get_variable(name=\"biases3\", shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
    "        layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
    "\n",
    "    # Output Layer\n",
    "    with tf.variable_scope('output'):\n",
    "        weights = tf.get_variable(\"weights4\", shape=[layer_3_nodes, numbe zer())\n",
    "        biases = tf.get_variable(name=\"biases4\", shape=[number_of_outputs], initializer=tf.zeros_initializer())\n",
    "        prediction = tf.matmul(layer_3_output, weights) + biases\n",
    "\n",
    "    # Section Two: Define the cost function of the neural network that will measure prediction accuracy during training\n",
    "\n",
    "    with tf.variable_scope('cost'):\n",
    "        Y = tf.placeholder(tf.float32)\n",
    "        cost = tf.reduce_mean(abs(prediction-Y))\n",
    "    \n",
    "    # Section Three: Define the optimizer function that will be run to optimize the neural network\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize a session so that we can run TensorFlow operations\n",
    "    with tf.Session() as session:\n",
    "\n",
    "        # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Run the optimizer over and over to train the network.\n",
    "        # One epoch is one full run through the training data set.\n",
    "        for epoch in range(training_epochs):\n",
    "\n",
    "            # Feed in the training data and do one step of neural network training\n",
    "            session.run(optimizer, feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            # Every 5 training steps, log our progress\n",
    "            if epoch % 5 == 0:\n",
    "                training_cost = session.run(cost, feed_dict={X: X_train, Y:Y_train})\n",
    "                testing_cost = session.run(cost, feed_dict={X: X_test, Y:Y_test})\n",
    "\n",
    "                print(epoch, training_cost, testing_cost)\n",
    "\n",
    "        # Training is now complete!\n",
    "        print(\"Training is complete!\")\n",
    "\n",
    "        final_training_cost = session.run(cost, feed_dict={X: X_train, Y: Y_train})\n",
    "        final_testing_cost = session.run(cost, feed_dict={X: X_test, Y: Y_test})\n",
    "\n",
    "        print(\"Final Training cost: {}\".format(final_training_cost))\n",
    "        print(\"Final Testing cost: {}\".format(final_testing_cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Tensor Ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = description_features[900:901,0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-87b1071ad6a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \"\"\"\n\u001b[1;32m   1891\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1892\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# not doing input validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/ensemble/_gradient_boosting.pyx\u001b[0m in \u001b[0;36msklearn.ensemble._gradient_boosting.predict_stages\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "clf.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.4020\n",
      "MAE: 0.3440\n",
      "MAE: 0.4114\n",
      "MAE: 0.3694\n",
      "MAE: 0.3967\n",
      "avg 0.3846973938856226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "  \n",
    "    clf = RandomForestRegressor(max_depth=45, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-c6aa452743a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mavg_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score_result' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "    clf = DecisionTreeRegressor(max_depth=45)\n",
    "    clf.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-affde38913fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mavg_mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score_result' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "n_folds = 5\n",
    "avg_mad = 0\n",
    "skf = StratifiedKFold(score_result, n_folds)\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "for train_index, test_index in skf:\n",
    "    X_train, X_test = description_features[train_index], description_features[test_index]\n",
    "    y_train, y_test = score_result[train_index], score_result[test_index]\n",
    "    clf = AdaBoostRegressor(DecisionTreeRegressor(max_depth=24),\n",
    "                          n_estimators=300, random_state=rng)\n",
    "    clf.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "    mad = mean_absolute_error(y_test, clf.predict(X_test))\n",
    "    #print(\"MSE: %.4f\" % mse)\n",
    "    avg_mad += mad\n",
    "    print(\"MAE: %.4f\" % mad)\n",
    "print(\"avg\",avg_mad/n_folds)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
